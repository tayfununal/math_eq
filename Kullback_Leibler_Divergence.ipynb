{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kullback-Leibler_Divergence.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMMsG02xhz0WNGjeXSYBr2i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayfununal/math_eq/blob/main/Kullback_Leibler_Divergence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Kullback-Leibler Divergence**"
      ],
      "metadata": {
        "id": "QvlBd_ndbx6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll explain Kullback-Leibler divergence briefly in this study. Kullback-Leibler divergence is abbreviated as KL divergence in the literature. This method have used for specifying distance between given two distribution like p and q.\n",
        "\n",
        "For discrete distributions, the KL divergence is defined as follows:\n",
        "\n",
        "\\begin{align*}\n",
        "            KL(p \\parallel q) &≜ \\sum_{k=1}^{K}p_klog(\\frac{p_k}{q_k})  \n",
        "\\end{align*}\n",
        "\n",
        "For continuous distributions, the KL divergence is defined as follows:\n",
        "\n",
        "\\begin{align*}\n",
        "            KL(p \\parallel q) &≜ \\int p(x)log(\\frac{p(x)}{q(x)})dx  \n",
        "\\end{align*}\n",
        "\n",
        "**Example:** Let's $p\\sim \\mathcal{N}$($\\mu_1$,$\\sigma_1$) and $q \\sim \\mathcal{N}$($\\mu_2$,$\\sigma_2$) are both normal distribution. Find the $KL(p \\parallel q)$ according to continuous distribution. \n",
        "\n",
        "**Solution:**\n",
        "\n",
        "\\begin{align*}\n",
        "            KL(p \\parallel q) &≜ \\int p(x)log\\Bigg(\\frac{p(x)}{q(x)}\\Bigg)dx \\\\\n",
        "            &≜ \\int p(x) \\log\\Bigg(\\frac\n",
        "{\\frac{1}{\\sigma_1 \\sqrt {2π}}\\exp\\Big(-{\\frac{1}{2} (\\frac{x-\\mu_1}{\\sigma_1})^2\\Big)}} \n",
        "{\\frac{1}{\\sigma_2 \\sqrt {2π}} \\exp\\Big(-{\\frac{1}{2} (\\frac{x-\\mu_2}{\\sigma_2})^2\\Big)}}\\Bigg) dx \\\\\n",
        "&≜\\int p(x) \\left[ log\\Bigg(\\frac\n",
        "{1}{\\sigma_1}\\exp\\Big(-{\\frac{1}{2} (\\frac{x-\\mu_1}{\\sigma_1})^2\\Big)} \\Bigg) - \n",
        "log\\Bigg(\\frac\n",
        "{1}{\\sigma_2} \\exp\\Big(-{\\frac{1}{2} (\\frac{x-\\mu_2}{\\sigma_2})^2\\Big)} \\Bigg)  \\right]dx \\\\\n",
        "&≜ \\int p(x) \\left[log\\Big(\\frac\n",
        "{1}{\\sigma_1}\\Big) + \\Big(-\\frac{1}{2}(\\frac{x-\\mu_1}{\\sigma_1})^2\\Big) - log\\Big(\\frac{1}{\\sigma_2}\\Big) - \\Big(-\\frac{1}{2}(\\frac{x-\\mu_2}{\\sigma_2})^2\\Big)\\right]dx \\\\\n",
        "&≜ \\int p(x) \\left[log\\Big(\\frac\n",
        "{1}{\\sigma_1}\\Big) - \\frac{1}{2}(\\frac{x-\\mu_1}{\\sigma_1})^2 - log\\Big(\\frac{1}{\\sigma_2}\\Big) + \\frac{1}{2}(\\frac{x-\\mu_2}{\\sigma_2})^2 \\right]dx \\\\\n",
        "&≜ \\int p(x) \\left[log\\Big(\\frac{\\sigma_2}{\\sigma_1}\\Big) - \\frac{1}{2\\sigma_1^2}(x-\\mu_1)^2 + \\frac{1}{2\\sigma_2^2}(x-\\mu_2)^2 \\right]dx \\\\\n",
        "&≜ log\\Big(\\frac{\\sigma_2}{\\sigma_1}\\Big) \\int p(x)dx - \\frac{1}{2\\sigma_1^2} \\int p(x)(x-\\mu_1)^2dx + \\frac{1}{2\\sigma_2^2} \\int p(x)(x-\\mu_2)^2dx \\hspace{1cm},\\hspace{1cm} \\int p(x)dx = 1 and \\int p(x)(x-\\mu_1)^2dx\n",
        "\\end{align*}\n"
      ],
      "metadata": {
        "id": "6_9WFdCVcBkI"
      }
    }
  ]
}